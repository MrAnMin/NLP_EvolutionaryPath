{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformer\n",
    "\n",
    "![image](../data/image/transformers.jpg)\n",
    "\n",
    "Transformer分为两个部分\n",
    "- 编码器：负责将输入序列转换为一种表示\n",
    "- 解码器：根据这种表示生成输出序列\n",
    "\n",
    "Transformer分为两个部分使用了大量的自注意力、多头注意力、解码器-解码器注意力  \n",
    "\n",
    "- 将输入序列的每个元素分别投影到三个不同的向量空间，得到Q，K，V向量。\n",
    "- 计算Q和K的点积，然后除以一个缩放因子（缩放因子为向量特征维度的平方根），得到注意力分数。\n",
    "- 用softmax函数对注意力分数进行归一化，得到注意力权重。\n",
    "- 将注意力权重与对应的V向量相乘，求和，得到自注意力的输出\n",
    "\n",
    "多头注意力，是让模型能够同时关注输入序列中的多个不同的表示子空间，从而捕捉更丰富的信息  \n",
    "\n",
    "注意力机制能够大幅提升语言模型性能，原因如下：\n",
    "- 注意力机制让Transformer能够在不同层次和不同位置捕捉输入序列中的依赖关系。\n",
    "- 注意力机制使得模型具有强大的表达能力，能够有效处理各种序列到序列任务。\n",
    "- 可以高度并行化，transformer训练速度得到提升。\n",
    "\n",
    "由于transformer模型不使用循环神经网络，因此没有位置信息，需要在输入序列添加位置编码，将每个词的位置信息加入到词向量中。  \n",
    "选用正弦和余弦函数对每个位置进行编码 编码后与词向量进行相加或拼接。因为正余弦函数具有平滑性和保留相对位置信息等优点。\n",
    "\n",
    "\n",
    "编码器内部由多个相同结构的层堆叠而成，每个层包含两个主要部分：\n",
    "- 多头注意力\n",
    "- 前馈神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import math\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from copy import deepcopy\n",
    "from matplotlib import pyplot as plt\n",
    "import random\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transformer类组-多头自注意力-缩放点积注意力\n",
    "\n",
    "ScaledDotProductAttention类  \n",
    "\n",
    "![image](../data/image/Atten.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention(query, key, value, mask=None):\n",
    "    '''\n",
    "    自注意力计算\n",
    "    query, key, value = [batch, head, token_len, d_k]\n",
    "    '''\n",
    "    d_k = query.size(-1)\n",
    "    # QK^T/srqt{d_k} [batch, head, tokenlen, tokenlen]\n",
    "    scores = torch.matmul(query, key.transpose(-2,-1)) / math.sqrt(d_k)\n",
    "    # [batch, head, tokenlen, tokenlen] \n",
    "    scores = scores.masked_fill(mask==True, -1e9)\n",
    "    atten_softmax = torch.softmax(scores, dim=-1)\n",
    "    return torch.matmul(atten_softmax, value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transformer类组-多头自注意力-多头注意力\n",
    "\n",
    "MultiHeadAttention类\n",
    "\n",
    "![image](../data/image/Attention.jpg)\n",
    "\n",
    "![image](../data/image/MultiHead.jpg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    '''\n",
    "    多头注意力机制\n",
    "    '''\n",
    "    def __init__(self, head, d_model):\n",
    "        '''\n",
    "        head:多头注意力，头数\n",
    "        d_model:token Embedding 的维度\n",
    "        '''\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.d_k = d_model // head\n",
    "        self.head = head\n",
    "        self.d_model = d_model\n",
    "        # 图中的1部分 \n",
    "        self.linear_query = nn.Linear(d_model, d_model)\n",
    "        # 图中的2部分 \n",
    "        self.linear_key = nn.Linear(d_model, d_model)\n",
    "        # 图中的3部分 \n",
    "        self.linear_value = nn.Linear(d_model, d_model)\n",
    "        # 图中的6部分 \n",
    "        self.linear_out = nn.Linear(d_model, d_model)\n",
    "        # 残差网络后的归一化\n",
    "        self.layer_norm = nn.LayerNorm(32)\n",
    "        \n",
    "        \n",
    "    def forward(self, query, key, value, mask=None):\n",
    "        # 复制一份query做残差用\n",
    "        clone_query = query.clone()\n",
    "        # 获得batch大小  \n",
    "        n_batch = query.size(0)\n",
    "        # 进行线性变换后，拆分为多头 \n",
    "        # [batch, token_len, d_model]->[batch,token_len,head, d_k]->[batch, head, token_len, d_k]\n",
    "        query = self.linear_query(query).view(n_batch, -1, self.head, self.d_k).transpose(1,2)\n",
    "        key = self.linear_key(key).view(n_batch, -1, self.head, self.d_k).transpose(1,2)\n",
    "        value = self.linear_value(value).view(n_batch, -1, self.head, self.d_k).transpose(1,2)\n",
    "        # 计算注意力 图中的4部分\n",
    "        enc_attention = attention(query, key, value, mask)\n",
    "        # 注意力计算后，把多头连接到一起 图中的5部分\n",
    "        # [batch, head, token_len, d_k] -> [batch, token_len, head, d_k] -> [batch, token_len, d_model]\n",
    "        enc_attention = enc_attention.transpose(1,2).contiguous().view(n_batch, -1, self.head * self.d_k)\n",
    "        # 连接后，进行一次线性变换，图中的6部分\n",
    "        outputs = self.linear_out(enc_attention)\n",
    "        # 最后残差add后，进行归一化\n",
    "        return self.layer_norm(outputs + clone_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 前馈网络(Position-wise Feed-Forward Network)\n",
    "FeedForward\n",
    "\n",
    "![image](../data/image/FFN.jpg)\n",
    "\n",
    "\n",
    "Transformer 为什么要加入前馈神经网络？  \n",
    "- 增强模型表达能力，通过前馈神经网络和自注意力机制的组合，可以学习到不同位置之间的长距离依赖关系。\n",
    "- 信息融合，将自注意力机制刷出的信息进行融合，每个位置上的信息在经过FFN后，都可以得到一个新的表示。\n",
    "- 层间传递"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, d_model:int, d_ff:int):\n",
    "        super(FeedForward, self).__init__()\n",
    "        self.fc_out = nn.Sequential(\n",
    "            nn.Linear(d_model, d_ff),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(d_ff, d_model)\n",
    "        )\n",
    "        self.layer_norm = nn.LayerNorm(32)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x_clone = x.clone()\n",
    "        out = self.fc_out(x)\n",
    "        return self.layer_norm(x_clone + out)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 位置编码\n",
    "\n",
    "![image](../data/image/pe.jpg)\n",
    "\n",
    "PE(pos,2i) = sin(pos/10000^{2i/d})  \n",
    "PE(pos,2i+1) = cos(pos/10000^{2i/d})  \n",
    "\n",
    "pos:token在句子中的位置，从0到seq_len-1  \n",
    "d:token embedding的维度  \n",
    "i:嵌入向量中的每个维度\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionEmbedding(nn.Module):\n",
    "    def __init__(self, voc_size:int, d_model:int, tokenLen:int):\n",
    "        '''\n",
    "        dim:d_model token特征的维度\n",
    "        max_len:句子最大长度\n",
    "        '''\n",
    "        super(PositionEmbedding, self).__init__()\n",
    "        pe = torch.zeros(tokenLen, d_model)\n",
    "        position = torch.arange(0, tokenLen).unsqueeze(1)\n",
    "        div_term = torch.exp((torch.arange(0, d_model, 2, dtype=torch.float) * torch.tensor(-(math.log(10000.0) / 32))))\n",
    "        pe[:,0::2] = torch.sin(position * div_term)\n",
    "        pe[:,1::2] = torch.cos(position * div_term)\n",
    "        \n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "        \n",
    "        self.embed = nn.Embedding(voc_size, d_model)\n",
    "        self.embed.weight.data.normal_(0, 0.1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        emb = self.embed(x)\n",
    "        emb = emb + self.pe\n",
    "        return emb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 编码器\n",
    "\n",
    "![image](../data/image/encoder.jpg)\n",
    "\n",
    "transformer 的编码器使用的是自注意力编码，采用的mask机制是填充  \n",
    "由于数据集中，每句话的长短都不一致，所以训练时，为了可以实现批次训练模型，  \n",
    "使用<PAD>做为填充，但是模型训练阶段每个词与<PAD>之间没有任何关系，所以在进行  \n",
    "mask时候需要把填充的部分去掉，也就是不计算注意力。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    '''\n",
    "    MultiHeadAttention -> Add & Norm -> Feed Forward -> Add & Norm\n",
    "    '''\n",
    "    def __init__(self, head, d_model, d_ff):\n",
    "        '''\n",
    "        head:多头注意力的头数\n",
    "        d_model:词向量的维度\n",
    "        d_ff:FFN网络中变换的维度\n",
    "        '''\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.attn = MultiHeadAttention(head, d_model)\n",
    "        self.feed_forward = FeedForward(d_model, d_ff)\n",
    "        \n",
    "    def forward(self, x, src_mask):\n",
    "        '''\n",
    "        编码器阶段采用自注意力编码，所以 query key value 一致\n",
    "        mask:编码器阶段，模型可以看到全部的输入信息，所以使用填充掩码，去掉因为保证数据长度一致时使用的PAD占位符\n",
    "        '''\n",
    "        atten = self.attn(x, x, x, src_mask)\n",
    "        outputs = self.feed_forward(atten)\n",
    "        return outputs\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, n_layer, head, d_model, d_ff):\n",
    "        '''\n",
    "        n_layer:编码器由多少个编码模块组成\n",
    "        head:多头注意力的头数\n",
    "        d_model:词向量的维度\n",
    "        d_ff:FFN网络中变换的维度\n",
    "        '''\n",
    "        super(Encoder, self).__init__()\n",
    "        self.encoder_layer_list = nn.ModuleList()\n",
    "        for _ in range(n_layer):\n",
    "            self.encoder_layer_list.append(EncoderLayer(head, d_model, d_ff))\n",
    "        \n",
    "    def forward(self, x, src_mask):\n",
    "        '''\n",
    "        x:输入的词\n",
    "        src_mask:填充掩码\n",
    "        '''\n",
    "#         x = self.layer_1(x, src_mask)\n",
    "#         x = self.layer_2(x, src_mask)\n",
    "#         x = self.layer_3(x, src_mask)\n",
    "        for encoder_layer in self.encoder_layer_list:\n",
    "            x = encoder_layer(x, src_mask)\n",
    "            \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 解码器\n",
    "![image](../data/image/EncoderDecoder.jpg)\n",
    "\n",
    "解码器层由2个注意力模块及一个FFN模块组成\n",
    "第一个注意力模块输入为预测出来的数据    \n",
    "为了使用模型更有利的训练，往往采用教师强制的方式进行训练，  \n",
    "在教师强制训练过程中将真实的输出作为下一步的时间的输入。  \n",
    "为了确保模型在预测当前位置时不会关注到未来信息，需要在第一个自注意力阶段加入后续注意力掩码，这个mask根绝目标序列计算得到 \n",
    "第二个注意力采用的是encoder和Decoder注意力，query为第一个注意力的输出，key和value为encoder层的输出  \n",
    "等同于使用解码器去查看在编码器中的权重。mask则采用输入序列计算得到填充掩码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    '''\n",
    "    MultiHeadAttention -> Add & Norm -> MultiHeadAttention -> Add & Norm -> Feed Forward -> Add & Norm\n",
    "    '''\n",
    "    def __init__(self, head, d_model, d_ff):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        self.decoder_self_atten = MultiHeadAttention(head, d_model)\n",
    "        self.encoder_decoder_atten = MultiHeadAttention(head, d_model)\n",
    "        self.feed_forward = FeedForward(d_model, d_ff)\n",
    "    \n",
    "    def forward(self, x, y, src_mask, trg_mask):\n",
    "        '''\n",
    "        src_mask:根据输入序列计算得到的填充掩码\n",
    "        trg_mask:根据目标序列计算得到填充掩码+后续掩码\n",
    "        '''\n",
    "        # 计算自身的输入序列中的atten\n",
    "        y = self.decoder_self_atten(y, y, y, trg_mask)\n",
    "        y = self.encoder_decoder_atten(y, x, x, src_mask)\n",
    "        ouputs = self.feed_forward(y)\n",
    "        return ouputs\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self,n_layer, head, d_model, d_ff):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.decoder_layer_list = nn.ModuleList()\n",
    "        for _ in range(n_layer):\n",
    "            self.decoder_layer_list.append(DecoderLayer(head, d_model, d_ff))\n",
    "            \n",
    "    def forward(self, x, y, mask_pad_x, mask_tril_y):\n",
    "        '''\n",
    "        query:解码器的query\n",
    "        mask_pad_x:根据输入序列计算得到的填充掩码\n",
    "        mask_tril_y:根据目标序列计算得到填充掩码+后续掩码\n",
    "        '''\n",
    "        for decoder_layer in self.decoder_layer_list:\n",
    "            y = decoder_layer(x, y, mask_pad_x, mask_tril_y)\n",
    "        return y\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 创建 mask 包括填充mask & 填充/后续mask  \n",
    "\n",
    "为了批量训练，保证输入序列长度一致，需要将小于长度的部分使用<PAD>填充，但是在训练模型时，pad部分是无用的，注意力不需要关注的，所以要去掉这一部分  \n",
    "    \n",
    "填充mask：去掉使用pad填充的部分\n",
    "pad的列是true时，意味着任何词对pad的注意力都是0  \n",
    "但是pad本身对其他词的注意力并不为0，所以pad行不是true  \n",
    "      \n",
    "后续mask：对于每个词而言，他只能看到他自己，和他之前的词，而看到之后的词语。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mask_pad(data, pad_idx):\n",
    "    '''\n",
    "    填充mask\n",
    "    data:数据 [batch, seqLen]\n",
    "    pad_idx: 掩码数\n",
    "    返回: [batch, 1, 1, seqlen]\n",
    "    '''\n",
    "    padding_mask = data == pad_idx\n",
    "    padding_mask = padding_mask.unsqueeze(1).unsqueeze(2)\n",
    "    return padding_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_combined_mask(data, pad_token_id=0):\n",
    "    #获得token长度\n",
    "    seqlen = data.size(1)\n",
    "    padding_mask = create_mask_pad(data, pad_token_id)\n",
    "    mask = torch.triu(torch.ones(seqlen, seqlen), diagonal=1)\n",
    "    look_ahead_mask = mask.bool().unsqueeze(0).unsqueeze(0)\n",
    "    combined_mask = torch.max(padding_mask, look_ahead_mask)\n",
    "    return combined_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.embed_x = PositionEmbedding(39, 32, 50)\n",
    "        self.embed_y = PositionEmbedding(39, 32, 50)\n",
    "        self.encoder = Encoder(3, 4, 32, 64)\n",
    "        self.decoder = Decoder(3, 4, 32, 64)\n",
    "        self.fc_out = nn.Linear(32, voc_size)\n",
    "        \n",
    "    def forward(self, x, y):\n",
    "        mask_pad_x = create_mask_pad(x, wordToidx['<PAD>'])\n",
    "        mask_combined_mask = create_combined_mask(y, wordToidx['<PAD>'])\n",
    "        x = self.embed_x(x)\n",
    "        y = self.embed_y(y)\n",
    "        x = self.encoder(x, mask_pad_x)\n",
    "        y = self.decoder(x, y, mask_pad_x, mask_combined_mask)\n",
    "        y = self.fc_out(y)\n",
    "        return y\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 生成训练数据\n",
    "\n",
    "原始数据：从 【0,1,2,3,4,5,6,7,8,9,q,w,e,r,t,y,u,i,o,p,a,s,d,f,g,h,j,k,l,z,x,c,v,b,n,m】随机选取30-48个字符  \n",
    "目标数据：原始数据的小写字母变成大写，数字变成9-原数字，倒序排列，并且头部重叠一次  \n",
    "例如：123456qwer->RREWQ345678"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = \"<SOS>,<EOS>,<PAD>,0,1,2,3,4,5,6,7,8,9,q,w,e,r,t,y,u,i,o,p,a,s,d,f,g,h,j,k,l,z,x,c,v,b,n,m\"\n",
    "\n",
    "wordToidx = {data:idx for idx, data in enumerate(words.split(','))}\n",
    "idxToword = {idx:data for idx, data in enumerate(words.split(','))}\n",
    "lab_wordToidx = {data.upper():idx for idx, data in idxToword.items()}\n",
    "lab_idxToword = {idx:data.upper() for idx, data in idxToword.items()}\n",
    "voc_size = len(wordToidx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    #组成序列的词的列表\n",
    "    words = [\n",
    "        '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'q', 'w', 'e', \n",
    "        'r', 't', 'y', 'u', 'i', 'o', 'p', 'a', 's', 'd', 'f', 'g', 'h',\n",
    "        'j', 'k', 'l', 'z', 'x', 'c', 'v', 'b', 'n', 'm'\n",
    "    ]\n",
    "    # 定义每个单词出现的概率\n",
    "    p = np.array([\n",
    "        1,2,3,4,5,6,7,8,9,10,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,\n",
    "        17,18,19,20,21,22,23,24,25,26\n",
    "    ])\n",
    "    p = p / p.sum()\n",
    "    # 随机选取n个\n",
    "    n = random.randint(30, 48)\n",
    "    x = np.random.choice(words, size=n, replace=True, p = p)\n",
    "    x = x.tolist()\n",
    "    \n",
    "    def f(i):\n",
    "        i = i.upper()\n",
    "        if not i.isdigit():\n",
    "            return i\n",
    "        i = 9 - int(i)\n",
    "        return str(i)\n",
    "    \n",
    "    y = [f(_x) for _x in x]\n",
    "    y = y + [y[-1]]\n",
    "    y = y[::-1]\n",
    "    \n",
    "    x = [\"<SOS>\"] + x + [\"<EOS>\"]\n",
    "    y = [\"<SOS>\"] + y + [\"<EOS>\"]\n",
    "    x = x + [\"<PAD>\"] * 50\n",
    "    y = y + [\"<PAD>\"] * 51\n",
    "    x = x[:50]\n",
    "    y = y[:51]\n",
    "    \n",
    "    x = [wordToidx[_x] for _x in x]\n",
    "    y = [lab_wordToidx[_y] for _y in y]\n",
    "    \n",
    "    x = torch.LongTensor(x)\n",
    "    y = torch.LongTensor(y)\n",
    "    \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _Dataset(Dataset):\n",
    "    def __init__(self):\n",
    "        super(_Dataset, self).__init__()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return 10000\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(dataset=_Dataset(), batch_size=4, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Transformer()\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optim = torch.optim.Adam(model.parameters(), lr=2e-3)\n",
    "# 会在预定的周期（step）按一定的因子（gamma）调整学习率，\n",
    "# step_size (int): 学习率下调的周期，单位为训练轮次（epochs）。\n",
    "# gamma (float, optional): 学习率调整的因子，新的学习率等于上一周期学习率乘以 gamma。默认值为 0.1。\n",
    "sched = torch.optim.lr_scheduler.StepLR(optim, step_size=3, gamma = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :0,i:0,loss:0.00060990359634161, accuracy:1.0\n",
      "epoch :0,i:200,loss:0.00023534431238658726, accuracy:1.0\n",
      "epoch :0,i:400,loss:0.0004288146155886352, accuracy:1.0\n",
      "epoch :0,i:600,loss:0.00025627174181863666, accuracy:1.0\n",
      "epoch :0,i:800,loss:0.0002982556470669806, accuracy:1.0\n",
      "epoch :0,i:1000,loss:0.0003540038305800408, accuracy:1.0\n",
      "epoch :0,i:1200,loss:0.00017349974950775504, accuracy:1.0\n",
      "epoch :0,i:1400,loss:0.0003045308985747397, accuracy:1.0\n",
      "epoch :0,i:1600,loss:0.00011168561468366534, accuracy:1.0\n",
      "epoch :0,i:1800,loss:0.0001509154390078038, accuracy:1.0\n",
      "epoch :0,i:2000,loss:0.00011977414396824315, accuracy:1.0\n",
      "epoch :0,i:2200,loss:7.015308801783249e-05, accuracy:1.0\n",
      "epoch :0,i:2400,loss:6.23313317191787e-05, accuracy:1.0\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1):\n",
    "    for i, (x, y) in enumerate(loader):\n",
    "        pred = model(x, y[:,:-1])\n",
    "        pred = pred.reshape(-1, voc_size)\n",
    "        y = y[:, 1:].reshape(-1)\n",
    "        loss = loss_func(pred, y)\n",
    "        \n",
    "        # <PAD>的不进行loss操作\n",
    "        select = y!= lab_wordToidx['<PAD>']\n",
    "        y = y[select]\n",
    "        pred = pred[select]\n",
    "        \n",
    "        loss = loss_func(pred, y)\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        \n",
    "        if i % 200 == 0:\n",
    "            #dim=1维度上的最大的数的索引\n",
    "            pred = pred.argmax(1)\n",
    "            correct = (pred == y).sum().item()\n",
    "            accuracy = correct / len(pred)\n",
    "            print(f\"epoch :{epoch},i:{i},loss:{loss.item()}, accuracy:{accuracy}\")\n",
    "            \n",
    "    sched.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x):\n",
    "    # x = [1, 50]\n",
    "    model.eval()\n",
    "\n",
    "    # [1, 1, 50, 50]\n",
    "    mask_pad_x = create_mask_pad(x, wordToidx['<PAD>'])\n",
    "\n",
    "    # 初始化输出,这个是固定值\n",
    "    # [1, 50]\n",
    "    # [[0,2,2,2...]]\n",
    "    target = [lab_wordToidx['<SOS>']] + [lab_wordToidx['<PAD>']] * 49\n",
    "    target = torch.LongTensor(target).unsqueeze(0)\n",
    "\n",
    "    # x编码,添加位置信息\n",
    "    # [1, 50] -> [1, 50, 32]\n",
    "    x = model.embed_x(x)\n",
    "\n",
    "    # 编码层计算,维度不变\n",
    "    # [1, 50, 32] -> [1, 50, 32]\n",
    "    x = model.encoder(x, mask_pad_x)\n",
    "\n",
    "    # 遍历生成第1个词到第49个词\n",
    "    for i in range(49):\n",
    "        # [1, 50]\n",
    "        y = target\n",
    "\n",
    "        # [1, 1, 50, 50]\n",
    "        mask_tril_y = create_combined_mask(y, lab_wordToidx[\"<PAD>\"])\n",
    "\n",
    "        # y编码,添加位置信息\n",
    "        # [1, 50] -> [1, 50, 32]\n",
    "        y = model.embed_y(y)\n",
    "\n",
    "        # 解码层计算,维度不变\n",
    "        # [1, 50, 32],[1, 50, 32] -> [1, 50, 32]\n",
    "        y = model.decoder(x, y, mask_pad_x, mask_tril_y)\n",
    "\n",
    "        # 全连接输出,39分类\n",
    "        # [1, 50, 32] -> [1, 50, 39]\n",
    "        out = model.fc_out(y)\n",
    "\n",
    "        # 取出当前词的输出\n",
    "        # [1, 50, 39] -> [1, 39]\n",
    "        out = out[:, i, :]\n",
    "\n",
    "        # 取出分类结果\n",
    "        # [1, 39] -> [1]\n",
    "        out = out.argmax(dim=1).detach()\n",
    "\n",
    "        # 以当前词预测下一个词,填到结果中\n",
    "        target[:, i + 1] = out\n",
    "\n",
    "    return target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "<SOS>jucoarmlxxzljdmy3nzpvuny7omzmc5xknjbkxkm4i<EOS><PAD><PAD><PAD><PAD><PAD><PAD>\n",
      "<SOS>II5MKXKBJNKX4CMZMO2YNUVPZN6YMDJLZXXLMRAOCUJ<EOS><PAD><PAD><PAD><PAD><PAD><PAD>\n",
      "<SOS>II5MKXKBJNKX4CMZMO2YNUVPZN6YMDJLZXXLMRAOCUJ<EOS><EOS><EOS><EOS><EOS><EOS>\n",
      "1\n",
      "<SOS>vldtglvbpz3gblv4zkcnlk8axclahh6b6lcf<EOS><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\n",
      "<SOS>FFCL3B3HHALCXA1KLNCKZ5VLBG6ZPBVLGTDLV<EOS><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\n",
      "<SOS>FFCL3B3HHALCXA1KLNCKZ5VLBG6ZPBVLGTDLV<EOS><EOS><EOS><EOS><EOS><EOS><EOS><EOS><EOS><EOS><EOS><EOS>\n",
      "2\n",
      "<SOS>x3yxhg5njsntlxc61lkmehoxyz5vosghbfb7mxvnazmz5<EOS><PAD><PAD><PAD>\n",
      "<SOS>44ZMZANVXM2BFBHGSOV4ZYXOHEMKL83CXLTNSJN4GHXY6X<EOS><PAD><PAD><PAD>\n",
      "<SOS>44ZMZANVXM2BFBHGSOV4ZYXOHEMKL83CXLTNSJN4GHXY6X<EOS><EOS><EOS>\n",
      "3\n",
      "<SOS>xgvwlumanfrmgnwnsyfmskvjn4lxod7mhx<EOS><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\n",
      "<SOS>XXHM2DOXL5NJVKSMFYSNWNGMRFNAMULWVGX<EOS><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\n",
      "<SOS>XXHM2DOXL5NJVKSMFYSNWNGMRFNAMULWVGX<EOS><EOS><EOS><EOS><EOS><EOS><EOS><EOS><EOS><EOS><EOS><EOS><EOS><EOS>\n"
     ]
    }
   ],
   "source": [
    "for i, (x, y) in enumerate(loader):\n",
    "    break\n",
    "\n",
    "for i in range(4):\n",
    "    print(i)\n",
    "    print(''.join([idxToword[i] for i in x[i].tolist()]))\n",
    "    print(''.join([lab_idxToword[i] for i in y[i].tolist()]))\n",
    "    print(''.join([lab_idxToword[i] for i in predict(x[i].unsqueeze(0))[0].tolist()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-ENV",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
